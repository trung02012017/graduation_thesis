\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\citation{holland1992genetic}
\citation{masadeh2019sea}
\citation{chawla2018levy}
\citation{wang2011enhanced}
\citation{omran2010improving}
\citation{wang2016opposition}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:introduction}{{1}{7}{Introduction}{chapter.1}{}}
\citation{wang2003particle}
\citation{yuan2004survey}
\citation{karmakar2002generic}
\citation{hore2011edge}
\citation{ruder2016overview}
\citation{liu2013experimental}
\citation{aljarah2018optimizing}
\citation{castillo2000g}
\citation{nasseri2008optimized}
\citation{kawam2012metaheuristic}
\citation{nikravesh2015towards}
\citation{lorido2012auto}
\citation{holland1992genetic}
\citation{koza1997genetic}
\citation{fleetwood2004introduction}
\citation{simon2008biogeography}
\citation{salcedo2013novel}
\citation{eberhart1995particle}
\citation{dorigo1999ant}
\citation{abbass2001mbo}
\citation{passino2002biomimicry}
\citation{basturk2006artificial}
\citation{yang2009firefly}
\citation{yang2012bat}
\citation{kaveh2013new}
\citation{mirjalili2014grey}
\citation{mirjalili2016whale}
\citation{yazdani2016lion}
\citation{dhiman2019seagull}
\citation{masadeh2019sea}
\citation{erol2006new}
\citation{rashedi2009gsa}
\citation{kaveh2010novel}
\citation{formato2007central}
\citation{alatas2011acroa}
\citation{hatamlou2013black}
\citation{kaveh2012new}
\citation{du2006small}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Materials and background}{11}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:background}{{2}{11}{Materials and background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Meta-heuristic Optimization}{11}{section.2.1}}
\newlabel{sec:meta_heuristic}{{2.1}{11}{Meta-heuristic Optimization}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Idea and motivation}{11}{subsection.2.1.1}}
\citation{eberhart1995particle}
\citation{dorigo1999ant}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Swarm-based optimization algorithms developed in literature.\relax }}{12}{table.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tbl_swarm_algos}{{2.1}{12}{Swarm-based optimization algorithms developed in literature.\relax }{table.caption.4}{}}
\citation{geem2001new}
\citation{rao2011teaching}
\citation{kashan2014league}
\citation{de1989tabu}
\citation{kaveh2014colliding}
\citation{kennedy2010particle}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Particle Swarm Optimization (PSO)}{13}{subsection.2.1.2}}
\newlabel{pso_standard}{{2.1.2}{13}{Particle Swarm Optimization (PSO)}{subsection.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces PSO flowchart\relax }}{13}{figure.caption.5}}
\newlabel{fig_pso_algo}{{2.1}{13}{PSO flowchart\relax }{figure.caption.5}{}}
\newlabel{eq_pso_1}{{2.1}{13}{Particle Swarm Optimization (PSO)}{equation.2.1.1}{}}
\newlabel{eq_pso_2}{{2.2}{13}{Particle Swarm Optimization (PSO)}{equation.2.1.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Sea Lion Optimization (SLnO)\relax }}{14}{algocf.1}}
\newlabel{algorithm_slno}{{1}{14}{Sea Lion Optimization Algorithm (SLnO)}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Sea Lion Optimization Algorithm (SLnO)}{14}{subsection.2.1.3}}
\newlabel{slno_standard}{{2.1.3}{14}{Sea Lion Optimization Algorithm (SLnO)}{subsection.2.1.3}{}}
\citation{masadeh2019sea}
\newlabel{slno_eq1}{{2.3}{15}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.3}{}}
\newlabel{slno_eq2}{{2.4}{15}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.4}{}}
\newlabel{snlo_eq3}{{2.5}{15}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.5}{}}
\newlabel{snlo_eq4}{{2.6}{15}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.6}{}}
\citation{masadeh2019sea}
\newlabel{snlo_eq5}{{2.7}{16}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.7}{}}
\newlabel{slno_eq6}{{2.8}{16}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.8}{}}
\newlabel{slno_eq7}{{2.9}{16}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.9}{}}
\newlabel{slno_eq8}{{2.10}{16}{Sea Lion Optimization Algorithm (SLnO)}{equation.2.1.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Artificial Neural Network (ANN)}{17}{section.2.2}}
\newlabel{sec:ann}{{2.2}{17}{Artificial Neural Network (ANN)}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Activation functions}{17}{subsection.2.2.1}}
\newlabel{ann_act_func}{{2.2.1}{17}{Activation functions}{subsection.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Activation functions. Source: https://medium.com/@srnghn/deep-learning-overview-of-neurons-and-activation-functions-1d98286cf1e4\relax }}{17}{figure.caption.7}}
\newlabel{fig_activation}{{2.2}{17}{Activation functions. Source: https://medium.com/@srnghn/deep-learning-overview-of-neurons-and-activation-functions-1d98286cf1e4\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Loss functions}{18}{subsection.2.2.2}}
\newlabel{ann_loss_func}{{2.2.2}{18}{Loss functions}{subsection.2.2.2}{}}
\citation{rumelhart1988learning}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Backpropagation algorithm applied for FFNN with 1 hidden layer\relax }}{19}{algocf.2}}
\newlabel{algorithm_backprop}{{2}{19}{Backpropagation - the ANN Training Algorithm}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Backpropagation - the ANN Training Algorithm}{19}{subsection.2.2.3}}
\newlabel{ann_backprop_alg}{{2.2.3}{19}{Backpropagation - the ANN Training Algorithm}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Forward propagation phase}{19}{subsubsection.2.2.3.1}}
\citation{amiri2017survey}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Weights updating phase}{20}{subsubsection.2.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Well-known machine learning models for time-series prediction problem}{20}{subsection.2.2.4}}
\newlabel{wl_known_models}{{2.2.4}{20}{Well-known machine learning models for time-series prediction problem}{subsection.2.2.4}{}}
\citation{azoff1994neural}
\citation{koskela1996time}
\newlabel{eq_ffnn_1}{{2.11}{21}{Well-known machine learning models for time-series prediction problem}{equation.2.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces An example of MLPs model in time-series prediction.\relax }}{21}{figure.caption.9}}
\newlabel{fig_model_mlp}{{2.3}{21}{An example of MLPs model in time-series prediction.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.1}Multi-Layer Perceptrons (MLPs)}{21}{subsubsection.2.2.4.1}}
\newlabel{model_mlp}{{2.2.4.1}{21}{Multi-Layer Perceptrons (MLPs)}{subsubsection.2.2.4.1}{}}
\citation{warsito2018cascade}
\citation{zhang2000predicting}
\citation{connor1994recurrent}
\citation{chandra2012cooperative}
\newlabel{eq_mlp_1}{{2.12}{22}{Multi-Layer Perceptrons (MLPs)}{equation.2.2.12}{}}
\newlabel{eq_mlp_2}{{2.13}{22}{Multi-Layer Perceptrons (MLPs)}{equation.2.2.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.2}Cascade Forward Neural Network (CFNN)}{22}{subsubsection.2.2.4.2}}
\newlabel{model_cfnn}{{2.2.4.2}{22}{Cascade Forward Neural Network (CFNN)}{subsubsection.2.2.4.2}{}}
\newlabel{eq_cfnn_1}{{2.14}{22}{Cascade Forward Neural Network (CFNN)}{equation.2.2.14}{}}
\newlabel{eq_cfnn_2}{{2.15}{22}{Cascade Forward Neural Network (CFNN)}{equation.2.2.15}{}}
\newlabel{eq_cfnn_3}{{2.16}{22}{Cascade Forward Neural Network (CFNN)}{equation.2.2.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.3}Recurrent Neural Network (RNN)}{22}{subsubsection.2.2.4.3}}
\newlabel{model_rnn}{{2.2.4.3}{22}{Recurrent Neural Network (RNN)}{subsubsection.2.2.4.3}{}}
\citation{hochreiter1997long}
\citation{gers2002applying}
\citation{guo2016robust}
\citation{fu2016using}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces An example of CFNN model in time-series prediction.\relax }}{23}{figure.caption.10}}
\newlabel{fig_model_cfnn}{{2.4}{23}{An example of CFNN model in time-series prediction.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Traditional RNN architechture. Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\relax }}{23}{figure.caption.11}}
\newlabel{model_lstm_gru}{{2.5}{23}{Traditional RNN architechture. Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.4}Long Short-Term Memory (LSTM)}{23}{subsubsection.2.2.4.4}}
\citation{chung2014empirical}
\citation{langkvist2014review}
\citation{bone2000recurrent}
\newlabel{eq_lstm_1}{{2.17}{24}{Long Short-Term Memory (LSTM)}{equation.2.2.17}{}}
\newlabel{eq_lstm_2}{{2.18}{24}{Long Short-Term Memory (LSTM)}{equation.2.2.18}{}}
\newlabel{eq_lstm_3}{{2.19}{24}{Long Short-Term Memory (LSTM)}{equation.2.2.19}{}}
\newlabel{eq_lstm_4}{{2.20}{24}{Long Short-Term Memory (LSTM)}{equation.2.2.20}{}}
\newlabel{eq_lstm_5}{{2.21}{24}{Long Short-Term Memory (LSTM)}{equation.2.2.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces LSTM and GRU architechture. Source: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\relax }}{24}{figure.caption.12}}
\newlabel{model_lstm_gru}{{2.6}{24}{LSTM and GRU architechture. Source: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.5}Gated Recurrent Units (GRU)}{24}{subsubsection.2.2.4.5}}
\citation{mell2011nist}
\newlabel{eq_gru_1}{{2.22}{25}{Gated Recurrent Units (GRU)}{equation.2.2.22}{}}
\newlabel{eq_gru_2}{{2.23}{25}{Gated Recurrent Units (GRU)}{equation.2.2.23}{}}
\newlabel{eq_gru_3}{{2.24}{25}{Gated Recurrent Units (GRU)}{equation.2.2.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Auto-scaling problem in Cloud Computing}{25}{section.2.3}}
\newlabel{sec:application}{{2.3}{25}{Auto-scaling problem in Cloud Computing}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Cloud Computing}{25}{subsection.2.3.1}}
\newlabel{cloud}{{2.3.1}{25}{Cloud Computing}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Comparision between Traditional IT and three models of Cloud computing. (source: https://dachou.github.io/2018/09/28/cloud-service-models.html)\relax }}{26}{figure.caption.13}}
\newlabel{fig_cloud_models}{{2.7}{26}{Comparision between Traditional IT and three models of Cloud computing. (source: https://dachou.github.io/2018/09/28/cloud-service-models.html)\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Auto-scaling demand in Cloud Computing.}{26}{subsection.2.3.2}}
\newlabel{auto_scale}{{2.3.2}{26}{Auto-scaling demand in Cloud Computing}{subsection.2.3.2}{}}
\citation{chen2015efficient}
\citation{yang2013workload}
\citation{calheiros2014workload}
\citation{shahin2017automatic}
\citation{zhu2017deep}
\citation{tran2018multivariate}
\citation{masadeh2019sea}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Improved Sea Lion Optimization (ISLO) algorithm and Proposed Model for Auto-Scaling (ISLO-CFNN)}{28}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:improvements}{{3}{28}{Improved Sea Lion Optimization (ISLO) algorithm and Proposed Model for Auto-Scaling (ISLO-CFNN)}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Improved Sea Lion Optimization (ISLO)}{28}{section.3.1}}
\newlabel{improved_ISLO}{{3.1}{28}{Improved Sea Lion Optimization (ISLO)}{section.3.1}{}}
\citation{eberhart1995particle}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Improved Sea Lion Optimization (ISLO)\relax }}{29}{algocf.3}}
\newlabel{algorithm_islo}{{3}{29}{Improved Sea Lion Optimization (ISLO)}{algocf.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Exploitation phase improvement}{29}{subsection.3.1.1}}
\newlabel{imprv_exploit}{{3.1.1}{29}{Exploitation phase improvement}{subsection.3.1.1}{}}
\newlabel{islo_eq1}{{3.1}{29}{Exploitation phase improvement}{equation.3.1.1}{}}
\newlabel{islo_eq2}{{3.2}{29}{Exploitation phase improvement}{equation.3.1.2}{}}
\citation{tizhoosh2005opposition}
\citation{tizhoosh2005opposition}
\citation{wang2007opposition}
\citation{tang2009enhanced}
\citation{rashid2010improved}
\citation{nguyen2019efficient}
\newlabel{islo_eq3}{{3.3}{30}{Exploitation phase improvement}{equation.3.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Exploration phase improvement}{30}{subsection.3.1.2}}
\newlabel{imprv_explore}{{3.1.2}{30}{Exploration phase improvement}{subsection.3.1.2}{}}
\newlabel{islo_eq4}{{3.4}{31}{Exploration phase improvement}{equation.3.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proposed model for auto-scaling problem in Cloud Computing}{31}{section.3.2}}
\newlabel{sec:proposed_model}{{3.2}{31}{Proposed model for auto-scaling problem in Cloud Computing}{section.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Time-series data and Supervised learning data comparison\relax }}{32}{table.caption.16}}
\newlabel{tbl_data_cmp}{{3.1}{32}{Time-series data and Supervised learning data comparison\relax }{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Proposed model design\relax }}{32}{figure.caption.15}}
\newlabel{fig_model_phases}{{3.1}{32}{Proposed model design\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Collecting data}{32}{subsection.3.2.1}}
\newlabel{collect_data}{{3.2.1}{32}{Collecting data}{subsection.3.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Example of data transformation using Sliding window method\relax }}{33}{table.caption.17}}
\newlabel{tbl_sliding_window}{{3.2}{33}{Example of data transformation using Sliding window method\relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Data pre-processing}{33}{subsection.3.2.2}}
\newlabel{data-pre}{{3.2.2}{33}{Data pre-processing}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Building and Training model}{33}{subsection.3.2.3}}
\newlabel{main_model}{{3.2.3}{33}{Building and Training model}{subsection.3.2.3}{}}
\newlabel{eq_length_solution}{{3.5}{34}{Building and Training model}{equation.3.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Encoding process transforming a parameter set in CFNN into an agent in ISLO algorithm. ($W^*$ indicates weights and biases between 2 layers)\relax }}{34}{figure.caption.18}}
\newlabel{fig_solution_encode}{{3.2}{34}{Encoding process transforming a parameter set in CFNN into an agent in ISLO algorithm. ($W^*$ indicates weights and biases between 2 layers)\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The work flow of ISLO-CFNN model.\relax }}{35}{figure.caption.19}}
\newlabel{fig_islo_cfnn_workflow}{{3.3}{35}{The work flow of ISLO-CFNN model.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Deploy prediction model}{35}{subsection.3.2.4}}
\newlabel{deploy}{{3.2.4}{35}{Deploy prediction model}{subsection.3.2.4}{}}
\citation{liang2013problem}
\citation{liang2014problem}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiments}{36}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:experiments}{{4}{36}{Experiments}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Theoretical experiments}{36}{section.4.1}}
\newlabel{sec:exp_theory}{{4.1}{36}{Theoretical experiments}{section.4.1}{}}
\citation{whitley1994genetic}
\citation{kennedy2010particle}
\citation{mirjalili2016whale}
\citation{masadeh2019sea}
\citation{kaveh2016novel}
\newlabel{subfig:uni}{{4.1a}{37}{Unimodal\relax }{figure.caption.20}{}}
\newlabel{sub@subfig:uni}{{a}{37}{Unimodal\relax }{figure.caption.20}{}}
\newlabel{subfig:multi}{{4.1b}{37}{Multimodal\relax }{figure.caption.20}{}}
\newlabel{sub@subfig:multi}{{b}{37}{Multimodal\relax }{figure.caption.20}{}}
\newlabel{subfig:hybrid}{{4.1c}{37}{Hybrid\relax }{figure.caption.20}{}}
\newlabel{sub@subfig:hybrid}{{c}{37}{Hybrid\relax }{figure.caption.20}{}}
\newlabel{subfig:compos}{{4.1d}{37}{Composition\relax }{figure.caption.20}{}}
\newlabel{sub@subfig:compos}{{d}{37}{Composition\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Examples of 3D plot for each kind of benchmark functions.\relax }}{37}{figure.caption.20}}
\newlabel{fig_functions}{{4.1}{37}{Examples of 3D plot for each kind of benchmark functions.\relax }{figure.caption.20}{}}
\citation{zhang2018queuing}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Description of unimodal benchmark functions\relax }}{38}{table.caption.21}}
\newlabel{tbl_uni_funcs}{{4.1}{38}{Description of unimodal benchmark functions\relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Description of multimodal benchmark functions\relax }}{38}{table.caption.22}}
\newlabel{tbl_multi_funcs}{{4.2}{38}{Description of multimodal benchmark functions\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Evaluation method and Parameter settings}{38}{subsection.4.1.1}}
\newlabel{eq_mean}{{4.1}{38}{Evaluation method and Parameter settings}{equation.4.1.1}{}}
\newlabel{eq_std}{{4.2}{38}{Evaluation method and Parameter settings}{equation.4.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Description of hybrid benchmark functions\relax }}{39}{table.caption.23}}
\newlabel{tbl_hybrid_funcs}{{4.3}{39}{Description of hybrid benchmark functions\relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Experiment results and discussion}{39}{subsection.4.1.2}}
\newlabel{exp_results}{{4.1.2}{39}{Experiment results and discussion}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2.1}Unimodal and Multimodal benchmark functions}{39}{subsubsection.4.1.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Description of composition benchmark functions\relax }}{40}{table.caption.24}}
\newlabel{tbl_compos_funcs}{{4.4}{40}{Description of composition benchmark functions\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Comparison of optimization results obtained for the unimodal and multimodal functions\relax }}{41}{table.caption.25}}
\newlabel{tbl_results_uni_multi}{{4.5}{41}{Comparison of optimization results obtained for the unimodal and multimodal functions\relax }{table.caption.25}{}}
\newlabel{subfig:uni_convergence}{{4.2a}{42}{Unimodal\relax }{figure.caption.26}{}}
\newlabel{sub@subfig:uni_convergence}{{a}{42}{Unimodal\relax }{figure.caption.26}{}}
\newlabel{subfig:multi_convergence}{{4.2b}{42}{Multimodal\relax }{figure.caption.26}{}}
\newlabel{sub@subfig:multi_convergence}{{b}{42}{Multimodal\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Convergence speed of each algorithm on unimodal (a) and multimodal (b) functions.\relax }}{42}{figure.caption.26}}
\newlabel{fig_uni_multi_convergence}{{4.2}{42}{Convergence speed of each algorithm on unimodal (a) and multimodal (b) functions.\relax }{figure.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Comparison of optimization results obtained for the hybrid and composition benchmark functions\relax }}{43}{table.caption.27}}
\newlabel{tbl_results_hybrid_compos}{{4.6}{43}{Comparison of optimization results obtained for the hybrid and composition benchmark functions\relax }{table.caption.27}{}}
\newlabel{subfig:hybrid_convergence}{{4.3a}{44}{Hybrid\relax }{figure.caption.28}{}}
\newlabel{sub@subfig:hybrid_convergence}{{a}{44}{Hybrid\relax }{figure.caption.28}{}}
\newlabel{subfig:compos_convergence}{{4.3b}{44}{Composition\relax }{figure.caption.28}{}}
\newlabel{sub@subfig:compos_convergence}{{b}{44}{Composition\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Convergence speed of each algorithm on hybrid (a) and composition (b) functions.\relax }}{44}{figure.caption.28}}
\newlabel{fig_hybrid_compos_convergence}{{4.3}{44}{Convergence speed of each algorithm on hybrid (a) and composition (b) functions.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2.2}Hybrid and Composition benchmark functions}{44}{subsubsection.4.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Application}{45}{section.4.2}}
\newlabel{sec:exp_app}{{4.2}{45}{Application}{section.4.2}{}}
\citation{reiss2011google}
\citation{cortez2012multi}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Dataset and Set up}{46}{subsection.4.2.1}}
\newlabel{exp:data}{{4.2.1}{46}{Dataset and Set up}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.1}Google Trace dataset}{46}{subsubsection.4.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Visualization of Google Trace CPU (left) and Google Trace RAM (right) datasets.\relax }}{46}{figure.caption.29}}
\newlabel{fig_data_ggtrace}{{4.4}{46}{Visualization of Google Trace CPU (left) and Google Trace RAM (right) datasets.\relax }{figure.caption.29}{}}
\citation{fu2016using}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.2}EU Internet Traffic and UK Internet Traffic datasets}{47}{subsubsection.4.2.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Visualization of EU Internet Traffic (left) and UK Internet Traffic (right) datasets.\relax }}{47}{figure.caption.30}}
\newlabel{fig_data_it}{{4.5}{47}{Visualization of EU Internet Traffic (left) and UK Internet Traffic (right) datasets.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Parameter Setting and Evaluation Metrics}{47}{subsection.4.2.2}}
\citation{eberhart1995particle}
\citation{masadeh2019sea}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Results and Discussion}{48}{subsection.4.2.3}}
\newlabel{Results_app}{{4.2.3}{48}{Results and Discussion}{subsection.4.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.1}Accuracy comparision}{48}{subsubsection.4.2.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Comparision between models on each dataset by different measurements.\relax }}{49}{table.caption.31}}
\newlabel{tbl_result_app}{{4.7}{49}{Comparision between models on each dataset by different measurements.\relax }{table.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Performance comparision between ISLO-CFNN and different recurrent-based deep learning models on Google Trace CPU data.\relax }}{50}{figure.caption.32}}
\newlabel{fig_result_cpu_islo_rnn}{{4.6}{50}{Performance comparision between ISLO-CFNN and different recurrent-based deep learning models on Google Trace CPU data.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Performance comparision between ISLO and other algorithms including Gradient Descent, PSO and SLnO on optimizing CFNN (Google Trace RAM data).\relax }}{50}{figure.caption.33}}
\newlabel{fig_result_ram}{{4.7}{50}{Performance comparision between ISLO and other algorithms including Gradient Descent, PSO and SLnO on optimizing CFNN (Google Trace RAM data).\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.2}Run-time comparision}{51}{subsubsection.4.2.3.2}}
\bibstyle{plain}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions and Future work}{52}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:conclusion}{{5}{52}{Conclusions and Future work}{chapter.5}{}}
\bibcite{abbass2001mbo}{1}
\bibcite{alatas2011acroa}{2}
\bibcite{aljarah2018optimizing}{3}
\bibcite{amiri2017survey}{4}
\bibcite{azoff1994neural}{5}
\bibcite{basturk2006artificial}{6}
\bibcite{bone2000recurrent}{7}
\bibcite{calheiros2014workload}{8}
\bibcite{castillo2000g}{9}
\bibcite{chandra2012cooperative}{10}
\bibcite{chawla2018levy}{11}
\bibcite{chen2015efficient}{12}
\bibcite{chung2014empirical}{13}
\bibcite{connor1994recurrent}{14}
\bibcite{cortez2012multi}{15}
\bibcite{de1989tabu}{16}
\bibcite{dhiman2019seagull}{17}
\bibcite{dorigo1999ant}{18}
\bibcite{du2006small}{19}
\bibcite{eberhart1995particle}{20}
\bibcite{erol2006new}{21}
\bibcite{fleetwood2004introduction}{22}
\bibcite{formato2007central}{23}
\bibcite{fu2016using}{24}
\bibcite{geem2001new}{25}
\bibcite{gers2002applying}{26}
\bibcite{Goodfellow-et-al-2016}{27}
\bibcite{guo2016robust}{28}
\bibcite{hatamlou2013black}{29}
\bibcite{hochreiter1997long}{30}
\bibcite{holland1992genetic}{31}
\bibcite{hore2011edge}{32}
\bibcite{karmakar2002generic}{33}
\bibcite{kashan2014league}{34}
\bibcite{kaveh2013new}{35}
\bibcite{kaveh2012new}{36}
\bibcite{kaveh2010novel}{37}
\bibcite{kaveh2016novel}{38}
\bibcite{kaveh2014colliding}{39}
\bibcite{kawam2012metaheuristic}{40}
\bibcite{kennedy2010particle}{41}
\bibcite{koskela1996time}{42}
\bibcite{koza1997genetic}{43}
\bibcite{langkvist2014review}{44}
\bibcite{liang2013problem}{45}
\bibcite{liang2014problem}{46}
\bibcite{liu2013experimental}{47}
\bibcite{lorido2012auto}{48}
\bibcite{masadeh2019sea}{49}
\bibcite{mell2011nist}{50}
\bibcite{mirjalili2016whale}{51}
\bibcite{mirjalili2014grey}{52}
\bibcite{nasseri2008optimized}{53}
\bibcite{nguyen2019efficient}{54}
\bibcite{nikravesh2015towards}{55}
\bibcite{omran2010improving}{56}
\bibcite{passino2002biomimicry}{57}
\bibcite{rao2011teaching}{58}
\bibcite{rashedi2009gsa}{59}
\bibcite{rashid2010improved}{60}
\bibcite{reiss2011google}{61}
\bibcite{ruder2016overview}{62}
\bibcite{rumelhart1988learning}{63}
\bibcite{salcedo2013novel}{64}
\bibcite{shahin2017automatic}{65}
\bibcite{simon2008biogeography}{66}
\bibcite{tang2009enhanced}{67}
\bibcite{tizhoosh2005opposition}{68}
\bibcite{tran2018multivariate}{69}
\bibcite{wang2016opposition}{70}
\bibcite{wang2007opposition}{71}
\bibcite{wang2011enhanced}{72}
\bibcite{wang2003particle}{73}
\bibcite{warsito2018cascade}{74}
\bibcite{whitley1994genetic}{75}
\bibcite{yang2013workload}{76}
\bibcite{yang2009firefly}{77}
\bibcite{yang2012bat}{78}
\bibcite{yazdani2016lion}{79}
\bibcite{yuan2004survey}{80}
\bibcite{zhang2000predicting}{81}
\bibcite{zhang2018queuing}{82}
\bibcite{zhu2017deep}{83}
