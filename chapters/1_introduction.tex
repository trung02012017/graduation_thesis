\documentclass[../main.tex]{subfiles}
\begin{document}
	Meta-heuristic optimiztion algorithms are becoming more and more popular in engineering application due to their advantages: they (i) have simple concepts and the ease of implementation; (ii) do not require gradient information; (iii) have the ability to avoid local minima and (iv) can be utilized in a wide range of real-world problems covering different aspects. Among those optimization models, there is a group of algorithm that are called nature-inspired meta-heuristic algorithms. They solve optimization issues by mathematically modelling biological or physical phenomena. They can be divided into three main categories: evolution-based, swarm-based and physics-based methods. 
	
	Evolution-based algorithm are derived from evolutionary laws in nature. The search process starts with randomly generated solutions which is continuously evolved over the course of generation. The most popular evolution-based algorithm is Generic Algorithm (GA) \cite{holland1992genetic}, which mathematically mimics the Darwinian's evolutionary laws. The second category is physics-based methods, which imitate physical principles in the universe such as Big Bang theory, gravitation of the Earth.  The third group of nature-inspired meta-heuristic optimization is swarm-based algorithms (or swarm intelligence (SI)). SI refers to the collectively intelligent activities emerging from a group of individuals called population, optimizing process is based on hunting and communication behaviors of animals in nature. The very first and most famous SI algorithm is Particle Swarm Optimization (PSO), which is a fundamental algorithm, and the inspiration for many later-born swarm-based optimizers. Additionally, it is worth mentioning here that there is a group of methods derived from human's activities in daily life, which is called human-based optimization algorithms. 
	
	Among these kinds of nature-inspired meta-heuristic algorithm, SI is the most popular one because of the ease in understanding and implementing. Due to the wide range of applications of these algorithms, in recent years, many swarm-inspired optimization algorithms have been introduced, going along with their variants and applications. Sea Lion Optimization (SLnO) is among these algorithms. It was first introduced in \cite{masadeh2019sea} for solving global-scale optimization problems. SLnO imitates the hunting behaviors of sea lions consisting of the way they encircle and capture preys or how they use their tail as well as their whiskers. It has been proven that SLnO can provide very competitive results compared with other well-known algorithms such as Particle Swarm Optimization (PSO), Grey Wolf Optimization (GWO) and Whale Optimization Algorithm (WOA) when working on different benchmark functions. However, like many other methods in swarm-based optimization, SLnO still faces demerits with regard to slow convergence speed, low precision and easily being stuck into local minimums due to the degradation of population diversity over the course of iteration. To improve the performance of these algorithms, there is a number of techniques proposed, and they are proven that they can work very effectively on different algorithms such as Levy-Flight trajectory-based method \cite{chawla2018levy}, opposition-based learning \cite{wang2011enhanced} \cite{omran2010improving} \cite{wang2016opposition} or using an idea from other algorithms, creating a hybrid version for improvements. However, there have not been any improved versions of SLnO even though there is several problems existing in this algorithm.

Because of their prominent advantages, such algorithms have been applied to various aspects including solving travelling salesman problem \cite{wang2003particle}, apllication to electric power system \cite{yuan2004survey} and image processing \cite{karmakar2002generic} \cite{hore2011edge}. Among applications of meta-heuristic algorithms, the use of them in optimizing artificial neural networks (ANNs) are emerging and being considered as a alternative for the backpropagation (BP) mechanism, which is the most well-know algorithm training ANNs. In the last three decade, ANNs have been developed and widely applied to classification, parttern recognition regression and forecasting problems. The ANNs' efficency mostly afftected by their learning process. For Multi-Layer Perceptron (MLPs), which is the most popular category of ANNs, the main method for training is gradient-based methods. The backpropagation algorithms and its variants \cite{ruder2016overview} are considered as the most well-known method for training MLPs. However, using gradient-based algorithms for optimizing MLPs still remains several drawbacks such as tendency being trapped in local minima, slow convergence and significant dependence on the initial stage of its parameters. In order to avoid complex gradient information as well as the disadvantages of gradient-based optimization, meta-heuristic optimization algorithms have been proposed as a reliable alternative for optimizing MLPs in the perspectives of parameters and network's structure. For example, as introduced in \cite{liu2013experimental}, GA and PSO algrithms are utilized to optimize parameters of Wavelet-MLP for wind speed prediction, or in \cite{aljarah2018optimizing} WOA is applied to simple MLPs for solving classification problems. Some other interesting applications of these optimizers on MLPs can be found in \cite{castillo2000g}, \cite{nasseri2008optimized} and \cite{kawam2012metaheuristic}. However, SLnO algorithm has not been used as an optimizer replacing BP algorithm in ANNs by any studies before.

	One of the most important problems that ANNs are used for solving is time-series prediction. This problem stems from time-series data, which is a series of data points recorded in order over a period of time in many sectors in real world such as weather, stocks and healthcare. Among many aspects that time-series prediction is related to, the auto-scaling issue in cloud environments is a big question that need to be tackled. This problem is given to  require cloud servers an ability to be adaptive and scalable, automatically recovering and allocating resources effectively. There is a number of fundamental methods proposed trying to solve this big issue including Autoregressive Moving Average (ARMA), Autoregressive Integrated Moving Average (ARIMA) and General Autoregressive Conditional
Heteroscedastic (GARCH), but today, with an incredible increase in the amount as well as complexity of data, these methods are becoming less and less competitive compared with others. In recent years, scholars have been trying to use meachine learning and deep learning neural networks (NNs) methods to tackle this time-series problem, and they have shown better performance as reported in \cite{nikravesh2015towards} and \cite{lorido2012auto}. Among these deep learning methods, RNN-based models such as traditional RNN, LSTM and GRU are widely chosen and applied to time-series forecasting in a wide range of aspects, and they have been showing very competitive performance compared with other deep learning models. However, in these models, BP algorithm is still used in the training process, so facing BP problems as mentioned above is unavoidable. Therefore, in this work we develop a model based on deep learning NNs and meta-heuristic algorithm trying to solve this auto-scaling problem.  
	
	All things considered, for the reasons mentioned above, in this paper, we propose 2 contributions: (i) improving SLnO algorithm to ISLO algorithm, and (ii) applying ISLO algorithm to optimizing a kind of ANNs called Cascade Feedforward Neural Network (CFNN) and utilizing this model (called ISLO-CFNN) trying to solve the given workload prediction demand in cloud computing environments. Firstly, an improved version of SLnO call Improved Sea Lion Optimization (ISLO) by embracing the idea from PSO, taking the best experience of each individual into account to improve SLnO's exploitation ability, and the idea of opposition-based learning for enhacing the use of exploration phase in SLnO. ISLO's performance is tested by 30 benchmark functions belonging to 4 kinds of functions: unimodal functions, multimodal functions, hybrid functions and composition functions. The results provided by ISLO are compared with other well-known meta-heuristic algorithms including GA, PSO, WOA, TWO, QSO and the original SLnO. The results show that ISLO provides superior final fitness values as well as decent convergence speed compared with the others. Secondly, we propose a model named ISLO-CFNN (CFNN being optimized by ISLO algorithm) to solve the time-series prediction problem deprived from  auto-scaling demand in cloud computing environments. ISLO-CFNN performance is experimented on 4 time-series datasets representing workload of server clusters and internet traffic. Its results are compared with other deep learning models that are well-known and widely used in time-series forecasting including traditional MLPs and CFNN with one hidden layer, RNN, LSTM and GRU in the term of accuracy. Optimizing capability of ISLO would be tested again by comparing with 2 other SI algorithms PSO and SLnO in optimizing CFNN. The figures provided by ISLO-CFNN show that this model is very competitive and can even bring more potential results compared with the others.
	
	The remainings of this thesis are organized as follows: the fundamental knowledge about swarm-based algorithms, ANNs and auto-scaling issues in cloud computing is presented in Chapter \ref{ch:background}. Chapter \ref{ch:improvements} describes our two main improvements on original SLnO algorithm, and the proposed model for tackling the above mentioned problem. Our experiments for testing the performance of ISLO algorithm and ISLO-CFNN model are discussed in Chapter \ref{ch:experiments}. Finally, the contribution and future work of this research are concluded in Chapter \ref{ch:conclusion}. 
\end{document}